{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb31de97-b3a1-42b7-ba51-e750ce528a71",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis  \n",
    "\n",
    "## What is EDA?\n",
    "EDA is the unstructured process of probing the data we haven’t seen before to understand more about it with a view to thinking about how we can use the data, and to discover what it reveals as insights at first glance.  \n",
    "\n",
    "At other times, we need to analyze some data with no particular objective in mind except to find out if it could be useful for anything at all.  \n",
    "Consider a situation where your manager points you to some data and asks you to do some analysis on it.  The data could be in a Google Drive, or a Github repo, or on a thumb drive.  It may have been received from a client, a customer or a vendor.  You may have a high level pointer to what the data is, for example you may know there is order history data, or invoice data, or web log data.  The ask may not be very specific, nor the goal clarified, but we would like to check the data out to see if there is something useful we can do with it.\n",
    "\n",
    "In other situations, we are looking for something specific, and are looking for the right data to analyze.  For example, we may be trying to to identify zip codes where to market our product.  We may be able to get data that provides us information on income, consumption, population characteristics etc that could help us with our task.  When we receive such data, we would like to find out if it is fit for purpose.  \n",
    "\n",
    "\n",
    "### Inquiries to conduct\n",
    "So when you get data that you do not know much about in advance, you start with exploratory data analysis, or EDA.  Possible inquiries you might like to conduct are:\n",
    "\n",
    "\n",
    " - How much data do we have - number of rows in the data?\n",
    " - How many columns, or fields do we have in the dataset?\n",
    " - Data types - which of the columns appear to be numeric, dates or strings?\n",
    " - Names of the columns, and do they tell us anything?\n",
    " - A visual review of a sample of the dataset\n",
    " - Completeness of the dataset, are missing values obvious?  Columns that are largely empty?\n",
    " - Unique values for columns that appear to be categorical, and how many observations of each category?\n",
    " - For numeric columns, the range of values (calculated from min and max values)\n",
    " - Distributions for the different columns, possibly graphed\n",
    " - Correlations between the different columns\n",
    "\n",
    "\n",
    "Exploratory Data Analysis (EDA) is generally the first activity performed to get a high level understanding of new data.  It employs a variety of graphical and summarization techniques to get a ‘sense of the data’.\n",
    "\n",
    "The purpose of Exploratory Data Analysis is to interrogate the data in an open-minded way with a view to understanding the structure of the data, uncover any prominent themes, identify important variables, detect obvious anomalies, consider missing values, review data types, obtain a visual understanding of the distribution of the data, understand correlations between variables, etc.  Not all these things can be discovered during EDA, but these are generally the things we look for when performing EDA. \n",
    "\n",
    "EDA is unstructured exploration, there is not a defined set of activities you must perform.  Generally, you probe the data, and depending upon what you discover, you ask more questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ba6bc-23bb-4857-8f20-e752b89ff6fb",
   "metadata": {},
   "source": [
    "## Introduction to Arrays\n",
    "\n",
    "Arrays, or collection of numbers, are fundamental to analytics at scale.  We will cover arrays from a NumPy lens exclusively, given how much NumPy dominates all array based manipulation.  \n",
    "\n",
    "NumPy is the underlying library for manipulating arrays in Python.  And arrays are really important for analytics.  The reason arrays are important is because many analytical algorithms will only accept arrays as input.  Deep learning networks will exclusively accept only arrays as input, though arrays are called **_tensors_** in the deep learning world.  In addition to this practical issue, data is much easier to manipulate, transform and perform mathematical operations on if it is expressed as an array.  \n",
    "\n",
    "NumPy underpins pandas as well as many other libraries.  So we may not be using it a great deal, but there will be situations where numpy is unavoidable.\n",
    "\n",
    "Below is a high level overview of what arrays are, and some basic array operations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8ff09-fde6-4fbc-ab32-8c0a36b0305d",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "### Multi-dimensional data\n",
    "\n",
    "Arrays have structure in the form of dimensions, and numbers sit at the intersection of these dimensions.  In a spreadsheet, you see two dimensions - one being the rows, represented as 1, 2, 3..., and the other the columns, repesented as A, B, C.  Numpy arrays can have any number of dimensions, even though dimensions beyond the third are humanly impossible to visualize.\n",
    "\n",
    "A numpy array when printed in Python encloses data for a dimension in square brackets.  The fundamental unit of an array of any size is a single one-dimensional row where numbers are separated by commas and enclosed in a set of square brackets, for example, `[1, 2, 3, 1]`.  Several of these will then be arranged within additional nested square brackets to make up the complete array.  To understand the idea of an array, mentally visualize a 2-dimensional array similar to a spreadsheet.  Every number within the array exists at the intersection of all of its dimensions.  In Python, each position along a dimension, more commonly called an _axis_, is represented by numbers starting with the first element being 0.  These positions are called indexes.\n",
    "\n",
    "The number of square brackets `[` gives the number of dimensions in the array.  Two are represented on screen, the rows and columns, like a 2D matrix.  But the screen is two-dimensional, and cannot display additional dimensions.  Therefore all other dimensions appear as repeats of rows and columns - look at the example next. The last two dimensions, eg here 3, 4 represent rows and columns.  The 2, the first one, means there are two sets of these rows and columns in the array!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861069c-1bea-4fbc-a7c3-ae8654fd5a6f",
   "metadata": {},
   "source": [
    "***\n",
    "### Creating arrays with Numpy  \n",
    "\n",
    "Everything that Numpy touches ends as an array, just like everything from a pandas function is a dataframe.  Easiest way to generate a random array is `np.random.randn(2,3)` which will give an array with dimensions 2,3.  You can pick any other dimensions too.  `randn` gives random normal numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363b19e2-7d15-4cc4-8e68-055d751a6074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mggy8413/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# import some libraries\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70f4247-9961-4430-8102-59bf5d381398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/jovyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b972fd29-8dfa-4c53-b7d5-2801a243dd30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53010939, -0.26013979, -1.36789056,  0.09318644])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a one dimensional array\n",
    "\n",
    "np.random.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2a09ee-5e0b-436d-a34b-20dc5384591f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06635634, -1.85709758, -1.06510315],\n",
       "       [-0.73035291,  0.89551841,  0.13411568]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2-dimensional array with random normal variables\n",
    "# np.random.seed(123)\n",
    "\n",
    "np.random.randn(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1768e6b1-5307-477a-9575-6c1421860d45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (2, 3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1, 3, 2, 4],\n",
       "        [2, 3, 2, 4],\n",
       "        [3, 1, 4, 4]],\n",
       "\n",
       "       [[2, 1, 4, 3],\n",
       "        [4, 1, 4, 1],\n",
       "        [1, 4, 4, 1]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 3-dimensional array with random integers\n",
    "\n",
    "x = np.random.randint(low = 1, high = 5, size = (2,3,4))\n",
    "print('Shape: ', x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90f4bc-b2c5-4e6c-bea6-bd448729f739",
   "metadata": {},
   "source": [
    "    \n",
    "Numpy axes numbers run from left to right, starting with the index 0.  So `x.shape` gives me 2, 3, 4 which means 2 is the 0th axis, 3 rows are the 1st axis and 4 columns are the 2nd axis.  \n",
    "  \n",
    "The shape of the above array is (2, 3, 4)  \n",
    "  \n",
    "axis = 0 means : (**2**, 3, 4)  \n",
    "axis = 1 means : (2, **3**, 4)  \n",
    "axis = 2 means : (2, 3, **4**)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c52dee-1fad-4855-bafa-ecf64cc80731",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the array is: (2, 3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.29751345, -0.79209536, -0.30800011, -0.11003366],\n",
       "        [ 0.89254248, -2.5404233 ,  0.11387802, -0.28652507],\n",
       "        [ 0.09047351,  1.89614923, -0.06056426, -0.15000823]],\n",
       "\n",
       "       [[ 0.10524661,  1.36260319, -0.69532639, -0.23330721],\n",
       "        [-1.78602706, -0.12680377, -0.81624271,  0.08893306],\n",
       "        [ 0.00924079,  0.5099789 ,  0.07351083,  0.70030037]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 3-dimensional array\n",
    "\n",
    "data = np.random.randn(2, 3, 4)\n",
    "print('The shape of the array is:', data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b50a57b-ce3e-483e-84fa-974c754ba7ed",
   "metadata": {},
   "source": [
    "> The number of `[` gives the number of dimensions in the array.  \n",
    "Two are represented on screen, the rows and columns.  All others appear afterwards.\n",
    "The last two dimensions, eg here 3, 4 represent rows and columns.  The 2, the first one, means there are two \n",
    "sets of these rows and columns in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570c7c1d-9b35-45bc-97e2-c960701c564d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[20, 87, 51, 48],\n",
       "         [29, 76, 28, 42]],\n",
       "\n",
       "        [[26,  6, 16, 69],\n",
       "         [94, 38, 27, 60]],\n",
       "\n",
       "        [[86, 38, 16, 85],\n",
       "         [74, 88, 32, 98]]],\n",
       "\n",
       "\n",
       "       [[[57, 30, 33, 71],\n",
       "         [60, 16, 22,  4]],\n",
       "\n",
       "        [[21, 24, 31, 69],\n",
       "         [49, 56, 30, 55]],\n",
       "\n",
       "        [[14, 85, 22, 77],\n",
       "         [ 3, 24, 73, 37]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let us add another dimension.  But this time random integers than random normal.\n",
    "# The random integer function (randint) requires specifying low and high for the uniform distribution.\n",
    "\n",
    "data = np.random.randint(low = 1, high = 100, size = (2,3,2,4))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d82b67-7750-4c18-be7b-1bde20e0173c",
   "metadata": {},
   "source": [
    "So there will be a collection of 2 rows x 4 columns matrices, repeated 3 times, and that entire set another 2 times. <br><br>\n",
    "And the 4 occurrences of `[[[[` means there are 4 dimensions to the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3082105-1bb8-4d18-88f2-4e6fe6418c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c789112-3b0a-4d4a-bfb2-635ed26a922d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting a list to an array\n",
    "\n",
    "list1 = list(range(12))\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f5d16f-5959-41e5-9502-92f752bb34b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 = np.array(list1)\n",
    "array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e17b1b86-4a4d-4a52-ba17-f8e481c47631",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This array1 is one dimensional, let us convert to a 3x4 array.\n",
    "array1.shape = (3,4)\n",
    "array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d7bac82-8407-441a-91b7-db181cb8b503",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create arrays of zeros\n",
    "array1 = np.zeros((2,3)) # The dimensions must be a tuple inside the brackets\n",
    "array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83fc13ad-ba56-4bcf-a6b7-f4cc076f9ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create arrays from a range\n",
    "array1 = np.arange((12))\n",
    "array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85ae6a33-0852-457f-a8e4-cb31c766c3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can reshape the dimensions of an array\n",
    "array1.reshape(3,4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c74598-a0aa-45e4-a863-5716174e9672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1],\n",
       "        [ 2,  3]],\n",
       "\n",
       "       [[ 4,  5],\n",
       "        [ 6,  7]],\n",
       "\n",
       "       [[ 8,  9],\n",
       "        [10, 11]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1.reshape(3,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a626f91-55db-4a0f-886a-d77609d207e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an array of 1's\n",
    "array1 = np.ones((3,5))\n",
    "array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b68f3d6-faa3-46ec-a141-01fb3b100514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates the identity matrix \n",
    "array1 = np.eye(4) \n",
    "array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15524d3b-3a6f-484b-9018-3685c7b050be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty array - useful if you need a place to keep data that will be generated later in the code.\n",
    "# It shows zeros but is actually empty\n",
    "\n",
    "np.empty([2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53210a3-5748-480e-ad1b-a73725bf0d5f",
   "metadata": {},
   "source": [
    "### Summarizing data along an axis  \n",
    "Putting the `axis = n` argument with a summarization function (eg, sum) makes the axis _n_ disappear, having been summarized into the function's results, leaving only the rest of the dimensions.  So `np.sum(array_name, axis = n)`, similarly `mean()`, `min()`, `median()`, `std()` etc will calculate the aggregation function by collapsing all the elements of the selected axis number into one and performing that operation.  See below using the sum function.  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8041911-519e-48af-9a07-e0f169d7e4c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76, 34, 43],\n",
       "       [42, 55, 78]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data = np.random.randint(low = 1, high = 100, size = (2,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84081b68-c779-4b05-bdbe-781dd968558b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([118,  89, 121])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So with axis = 0, the very first dimension, ie the 2 rows, will collapse leaving an array of shape (3,)\n",
    "x.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b6725c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([153, 175])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So with axis = 0, the very first dimension, ie the 2 rows, will collapse leaving an array of shape (2,)\n",
    "x.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e9c16-3fc8-46b3-9904-c10d19c31826",
   "metadata": {},
   "source": [
    "### Subsetting arrays ('slices')\n",
    "Python starts numbering things starting with zero, which means the first item is the 0th item.  \n",
    "\n",
    "The portion of the dimension you wish to select is given in the form `start:finish` where the `start` element is included, but the `finish` is excluded.  So `1:3` means include 1 and 2 but not 3.\n",
    "\n",
    "`:` means include everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0b4e6d4-e5cf-4830-8cca-f18bb8e8c187",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99, 90, 44, 72, 55],\n",
       "       [24,  5, 38, 81, 12],\n",
       "       [61, 35, 25, 46, 63]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 = np.random.randint(0, 100, (3,5))\n",
    "array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f5d2f59-b13f-4b9c-be11-ba9be55462fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99, 90],\n",
       "       [24,  5]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1[0:2, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37a94bec-6752-4c0c-a3b6-db112109b201",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99, 90],\n",
       "       [24,  5],\n",
       "       [61, 35]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1[:,0:2] # ':' means include everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b963c72-ca3e-4ce6-bb3c-89fa43aacc70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99, 90, 44, 72, 55],\n",
       "       [24,  5, 38, 81, 12]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4024490f-c4b3-4455-9d55-3c8b851ab9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99, 90, 44, 72, 55],\n",
       "       [24,  5, 38, 81, 12]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Slices are references to the original array.  So you if you need a copy, use the below:\n",
    "array1[0:2].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970df70-a278-4490-ad34-4dc651e6b753",
   "metadata": {},
   "source": [
    "Generally, use the above 'Long Form' way for slicing where you specify the indices for each dimension. Where everything is to be included, use `:`.  There are other short-cut methods of slicing, but can leave those as is.\n",
    "\n",
    "Imagine an array a1 with dimensions (3, 5, 2, 4).  This means:\n",
    " - This array has 3 arrays in it that have the dimensions (5, 2, 4)\n",
    " - Each of these 3 arrays have 5 additional arrays each in them of the dimension (2,4).  (So there are 3*5=15 of these 2x4 arrays)\n",
    " - Each of these (2,4) arrays has 2 one-dimensional arrays with 4 columns.\n",
    " \n",
    "If in the slice notation only a portion of what to include is specified, eg a1[0], then it means we are asking for the first one of these axes, ie the dimension parameters are specifying from the left of (3, 5, 2, 4).  It means give me the first of the 3 arrays with size (5,2,4).  \n",
    "\n",
    "If the slice notation says a1[0,1], then it means 0th element of the first dim, and 1st element of the second dim.\n",
    "\n",
    "Check it out using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "926838b4-3ef1-4f37-9485-f7c6a1cc4d54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[49, 32, 85,  3, 36],\n",
       "         [65, 67, 68, 82, 61]],\n",
       "\n",
       "        [[36, 79, 74, 71, 75],\n",
       "         [64, 86, 93, 51, 92]],\n",
       "\n",
       "        [[79, 76, 78, 51, 96],\n",
       "         [37, 56,  4, 46, 71]],\n",
       "\n",
       "        [[82, 67, 28, 72, 44],\n",
       "         [24, 89, 71,  2, 86]]],\n",
       "\n",
       "\n",
       "       [[[21, 89, 71, 38,  9],\n",
       "         [51, 32, 10, 38, 52]],\n",
       "\n",
       "        [[38, 11, 79, 54, 79],\n",
       "         [23, 24, 16, 88, 61]],\n",
       "\n",
       "        [[ 3,  4, 28, 60, 94],\n",
       "         [63, 83, 81,  1, 80]],\n",
       "\n",
       "        [[12, 14, 40, 63, 23],\n",
       "         [69, 79, 45, 90, 29]]],\n",
       "\n",
       "\n",
       "       [[[61, 51, 76, 72, 79],\n",
       "         [21, 40, 23, 73, 88]],\n",
       "\n",
       "        [[13, 15, 65, 76, 79],\n",
       "         [50, 24, 84,  4, 74]],\n",
       "\n",
       "        [[11, 39, 19, 61,  0],\n",
       "         [98, 87, 52, 77,  7]],\n",
       "\n",
       "        [[65, 46, 45, 52, 76],\n",
       "         [25, 17, 50, 55,  5]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.random.randint(0, 100, (3,4,2,5))\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d068c69f-1597-486e-b5ee-257fee352375",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52ffd5da-817d-4e1d-bf1a-3fe3c1443751",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[49, 32, 85,  3, 36],\n",
       "        [65, 67, 68, 82, 61]],\n",
       "\n",
       "       [[36, 79, 74, 71, 75],\n",
       "        [64, 86, 93, 51, 92]],\n",
       "\n",
       "       [[79, 76, 78, 51, 96],\n",
       "        [37, 56,  4, 46, 71]],\n",
       "\n",
       "       [[82, 67, 28, 72, 44],\n",
       "        [24, 89, 71,  2, 86]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0f36c67-7185-4b9a-91c2-d05d9ad5e2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36, 79, 74, 71, 75],\n",
       "       [64, 86, 93, 51, 92]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a64f90d-17c1-434f-b932-0ff75a2ed9c7",
   "metadata": {},
   "source": [
    "### More slicing: Picking selected rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08d166ef-abcd-4b33-8e2f-2b83ac6e2716",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29, 31, 36, 98, 27, 23, 91,  3, 65],\n",
       "       [36,  1, 17, 51, 45, 92, 70, 55, 65],\n",
       "       [85, 47, 84, 94, 30, 70, 17, 54,  8],\n",
       "       [69, 65, 94, 70, 99, 69, 19, 50, 76],\n",
       "       [60, 52,  8, 93, 68, 71, 72, 62, 32],\n",
       "       [94, 88, 13,  0, 45, 21, 30,  1, 26],\n",
       "       [83, 11, 12, 29, 41, 22, 69, 35, 22],\n",
       "       [55, 66, 54, 92, 14, 51, 30, 69, 60]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.random.randint(0, 100, (8,9))\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d267e5f-373e-4454-968a-3d4ae2c91e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 31, 36, 98, 27, 23, 91,  3, 65])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first row\n",
    "a1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da3de471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69, 65, 94, 70, 99, 69, 19, 50, 76])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the fourth row\n",
    "a1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6153fa18-b7c9-46e7-9031-af6b6b83bb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29, 31, 36, 98, 27, 23, 91,  3, 65],\n",
       "       [69, 65, 94, 70, 99, 69, 19, 50, 76]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first and the fourth row together\n",
    "a1[[0,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d64c4b3-f463-49ad-8ec0-e16135183322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29, 98],\n",
       "       [36, 51],\n",
       "       [85, 94],\n",
       "       [69, 70],\n",
       "       [60, 93],\n",
       "       [94,  0],\n",
       "       [83, 29],\n",
       "       [55, 92]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first and the fourth column\n",
    "a1[:,[0,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c93f1fbd-5e99-475f-b5e6-94f10b8c66e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29, 31],\n",
       "       [69, 65]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select subset of named rows and columns\n",
    "\n",
    "a1[[0, 3]][:,[0, 1]] # Named rows and columns.  \n",
    "\n",
    "# Note that a1[[0, 3],[0, 1]] does not work as expected, it selects two points (0,0)and (3,1).  \n",
    "# Really crazy but it is what it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca2bb78-5ad9-4fb2-b578-07516b69d7e2",
   "metadata": {},
   "source": [
    " ### Operations on arrays\n",
    " **All math on arrays is element wise, and scalars are multiplied/added with each element.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fd4db7e-2d4b-4e79-a862-70e21aa62d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103,  94,  48,  76,  59],\n",
       "       [ 28,   9,  42,  85,  16],\n",
       "       [ 65,  39,  29,  50,  67]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9836b3f3-07b2-4d14-8e21-a65460e54c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 > np.random.randint(0, 2, (3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "451cccd6-0ec4-4814-b810-43c6802ea8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101,  92,  46,  74,  57],\n",
       "       [ 26,   7,  40,  83,  14],\n",
       "       [ 63,  37,  27,  48,  65]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cf310bb-6d02-455b-8f50-e9671d55e365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(array1) # adds all the elements of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77cf8198-0027-482f-9005-c1ef29216ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([184, 130, 107, 199, 130])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(array1, axis = 0) # adds all elements of the array along a particular axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0be2701-4028-45bd-9867-74f1c6bf4c02",
   "metadata": {},
   "source": [
    "### Matrix math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4fe3a-ce99-4d66-b5e1-52cc1bcdba03",
   "metadata": {},
   "source": [
    "Numpy has arrays as well as matrices.  Matrices are 2D, arrays can have any number of dimensions. The only real difference between a matrix (type = `numpy.matrix`) and an array (type = `numpy.ndarray`) is that all array operations are element wise, ie the special R x C matrix multiplication does not apply to arrays.  However, for an array that is 2 x 2 in shape you can use the `@` operator to do matrix math.\n",
    "\n",
    "So that leaves matrices and arrays interchangeable in a practical sense.  Except that you can't do an inverse of an array using `.I` which you can for a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b737de51-2be3-44cd-927f-5c5e3490c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix 'm' and an array 'a' that are identical\n",
    "m = np.matrix(np.random.randint(0,10,(3,3)))\n",
    "a = np.array(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03c65257-dadb-49c6-b6ba-cc9563e13a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 5, 0],\n",
       "        [6, 3, 8],\n",
       "        [7, 4, 3]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "921df435-1df1-4799-9c9a-14840c847412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 5, 0],\n",
       "       [6, 3, 8],\n",
       "       [7, 4, 3]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976a67a-5519-45c3-bb9c-f70ea197466f",
   "metadata": {},
   "source": [
    "#### Transpose with a `.T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "406fdabc-2cf5-4223-8dfa-2d850a1cfb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 6, 7],\n",
       "        [5, 3, 4],\n",
       "        [0, 8, 3]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "910acadf-560e-4ca7-bd44-fcb38c7cfe6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 6, 7],\n",
       "       [5, 3, 4],\n",
       "       [0, 8, 3]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f588cb-7669-4e93-8cbf-2925d5c11d56",
   "metadata": {},
   "source": [
    "#### Inverse with a `.I` \n",
    "**Does not work for arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d978b50a-961e-4e80-b7ef-956ccc250d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.13772455, -0.08982036,  0.23952096],\n",
       "        [ 0.22754491,  0.01796407, -0.04790419],\n",
       "        [ 0.01796407,  0.18562874, -0.16167665]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c2f64-41b5-4a26-8945-84d4ead020dc",
   "metadata": {},
   "source": [
    "#### Matrix multiplication\n",
    "For matrices, just a `*` suffices for matrix multiplication.  If using arrays, use `@` for matrix multiplication, which also works for matrices.  So just to be safe, just use `@`.\n",
    "\n",
    "**Dot-product** is the same as row-by-column matrix multiplication, and is not elementwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc0eff59-8014-4bda-b51c-5cfa9b8e7280",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.matrix([[4, 3], [2, 1]])\n",
    "b=np.mat([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6f28d92-ab03-4271-87f5-4f46f0249ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[4, 3],\n",
       "        [2, 1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6eca2943-0ed7-426d-9541-7a0ced9dbefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28d26e13-3a25-4620-9385-ab39d7768a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[13, 20],\n",
       "        [ 5,  8]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "150b5de6-89b4-428d-a53f-d87d649a9f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[13, 20],\n",
       "        [ 5,  8]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "016e372b-a248-43b6-9b01-00cd14c4b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check with arrays\n",
    "a=np.array([[4, 3], [2, 1]])\n",
    "b=np.array([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a7d6d99-903d-4116-b942-f06c83189219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 20],\n",
       "       [ 5,  8]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b # does matrix multiplication.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ada35a33-e84a-4912-9243-7921fe7acfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 3],\n",
       "       [2, 1]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b46a23d-1050-4a25-ba74-bc99ee54671b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d70288cf-fb84-43d4-a8e3-652d15cd91cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 6],\n",
       "       [6, 4]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b # element-wise multiplication as a and b are arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba5a75-6398-4f99-82af-bf9f37a9f3c2",
   "metadata": {},
   "source": [
    "`@` is the same as `np.dot(a, b)`, which is just a longer fully spelled out function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6429cbb3-94f7-42dd-bdb3-458950d78b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 20],\n",
       "       [ 5,  8]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db344156-c962-4abb-906f-ba04ec214384",
   "metadata": {},
   "source": [
    "#### Exponents with matrices and arrays `**`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10794224-560f-43e5-a85c-51aee082b030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[4, 3],\n",
       "        [2, 1]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[4, 3], [2, 1]])\n",
    "m = np.matrix(a)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db194fc3-d009-4243-8d98-1d51d553ac05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  9],\n",
       "       [ 4,  1]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a**2 # Because a is an array, this will square each element of a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "72355665-ef7b-4780-955f-0508c92dfd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[22, 15],\n",
       "        [10,  7]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m**2 # Because m is a matrix, this will be read as m*m, and dot product of the matrix with itself will result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20acc49e-27a9-44b4-ab3c-63853f24dd83",
   "metadata": {},
   "source": [
    "which is same as `a@a`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47740e20-30b2-49c7-87f3-cc84f42cc68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22, 15],\n",
       "       [10,  7]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3b634-e461-4048-8578-8bf7ee233b28",
   "metadata": {},
   "source": [
    "#### Modulus, or size \n",
    "The modulus is just `sqrt(a^2 + b^2 + ....n^2)`, where a, b...n are elements of the vector, matrix or array.  Can be calculated using `np.linalg.norm(a)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a5b3945-0437-4b88-9f91-b49fb9b7e9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([4,3,2,1])\n",
    "np.linalg.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "53111a73-10d8-493c-8dda-06302816b71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as calculating manually\n",
    "(4**2 + 3**2 + 2**2 + 1**2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "33c1e668-8f04-46aa-8db0-baedc33a8faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f1a3e71-6389-4581-98c5-83e91fd4caeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c796351-698e-479f-961e-5ce3800b449d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[4, 3],\n",
       "        [2, 1]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "645d3c09-8ab3-4678-9620-6199fe40010e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "171dbc2e-d28b-4946-bd2e-d7ed33fa09d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 3, 0],\n",
       "        [8, 7, 5],\n",
       "        [0, 0, 6]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.matrix(np.random.randint(0,10,(3,3)))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ffb5d32a-4c11-41b5-ae7e-ee68c321b538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.527749258468683"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4eda9d4e-e1be-4d15-b985-373b2a30a6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 0 8 7 5 0 0 6]\n",
      "<class 'numpy.ndarray'>\n",
      "Manual calculation for norm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.527749258468683"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.ravel(m))\n",
    "print(type(np.ravel(m)))\n",
    "print('Manual calculation for norm')\n",
    "((np.ravel(m)**2).sum())**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92ce6d-d785-4dd2-ba29-651a5b73e138",
   "metadata": {},
   "source": [
    "#### Determinant of a matrix `np.linalg.det(a)`\n",
    "Used for calculating the inverse of a matrix, and only applies to square matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f49813d3-3b7e-40c7-8be0-68366a4e5e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-143.9999999999999"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992848d0-3a25-492d-8186-4bbc3a406de2",
   "metadata": {},
   "source": [
    "#### Converting from matrix to array and vice-versa\n",
    "`np.asmatrix` and `np.asarray` allow you to convert one to the other. Though above we have just used np.array and np.matrix without any issue.\n",
    "\n",
    "The above references: https://stackoverflow.com/questions/4151128/what-are-the-differences-between-numpy-arrays-and-matrices-which-one-should-i-u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc953bf-2b41-406b-b717-0a4cb2420905",
   "metadata": {},
   "source": [
    "#### Distances and angles between vectors\n",
    "**Size of a vector, angle between vectors, distance between vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae54297b-b8ac-433c-9b86-2c512e872f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = [1 2 3]\n",
      "b = [5 4 3]\n"
     ]
    }
   ],
   "source": [
    "# We set up two vectors a and b\n",
    "\n",
    "a = np.array([1,2,3]); b = np.array([5,4,3])\n",
    "print('a =',a)\n",
    "print('b =',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8eab5d2b-ad3a-4873-9f80-144fa297bbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416573867739413"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of the vector, computed as the root of the squares of each of the elements\n",
    "np.linalg.norm(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6b8ca056-143f-4bf9-90c8-476b1f27f621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.47213595499958"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distance between two vectors\n",
    "np.linalg.norm(a - b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7f75d0be-fbcb-4f83-bc79-e29d6dd83be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.47213595499958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.47213595499958"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which is the same as \n",
    "print(np.sqrt(np.dot(a, a) - 2 * np.dot(a, b) + np.dot(b, b)))\n",
    "(a@a + b@b - 2*a@b)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b220a495-95df-4351-bbe4-92c613ed4d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [5, 4, 3]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two vectors\n",
    "X = np.concatenate((a,b)).reshape(2,3)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0cd7011-5b7f-4d25-9608-81e05e169089",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Euclidean distance is the default metric for this function\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# from sklearn\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pairwise_distances\n\u001b[1;32m      4\u001b[0m pairwise_distances(X)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Euclidean distance is the default metric for this function\n",
    "# from sklearn\n",
    "from sklearn.metrics import pairwise_distances\n",
    "pairwise_distances(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61370750-e162-44b7-ac19-40b684f0ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle in radians between two vectors. To get the\n",
    "# answer in degrees, multiply by 180/pi, or 180/math.pi (after import math).  Also there is a function in math called\n",
    "# math.radians to get radians from degrees, or math.degrees(x) to convert angle x from radians to degrees.\n",
    "\n",
    "import math\n",
    "angle_in_radians = np.arccos(np.dot(a,b) / (np.linalg.norm(a) * np.linalg.norm(b))) \n",
    "angle_in_degrees = math.degrees(angle_in_radians)\n",
    "\n",
    "print('Angle in degrees =', angle_in_degrees)\n",
    "print('Angle in radians =', angle_in_radians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91853929-3bdb-49af-afc0-062af38aba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above using math.acos instead of np.arccos\n",
    "\n",
    "math.acos(np.dot(a,b) / (np.linalg.norm(a) * np.linalg.norm(b))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca905020-0d69-4389-ab98-6f934fbd57b3",
   "metadata": {},
   "source": [
    "#### Sorting with `argsort` \n",
    "Which is the same as sort, but  shows index numbers instead of the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e580b-3414-47b8-a7e3-ca474e16902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set up an array\n",
    "\n",
    "a = np.array([20,10,30,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf239a-fc8a-44ef-8ed2-984749db3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted indices\n",
    "\n",
    "np.argsort(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b0fd9-052c-44d8-92aa-fab6937cb238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the indices to get the sorted values\n",
    "\n",
    "a[np.argsort(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4a1c9-4561-4cdd-b46b-345cd8581710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descending sort indices\n",
    "\n",
    "np.argsort(a)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a13bbc-5bad-4dd7-8e4a-9c765d97d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descending sort values\n",
    "\n",
    "a[np.argsort(a)[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aafbc1e-6afd-457d-870c-8e263b05912f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e53c42d-1252-4c98-9608-26369dc06695",
   "metadata": {},
   "source": [
    "## Understanding DataFrames\n",
    "As we discussed in the prior section, understanding and manipulating arrays of numbers is fundamental to the data science process.  This is because nearly all ML and AI algorithms insist on being provided data arrays as inputs, and the NumPy library underpins almost all of data science.\n",
    "\n",
    "As we discussed, a NumPy array is essentially a collection of numbers.  This collection is organized along ‘dimensions’.  So NumPy objects are n-dimensional array objects, or _ndarray_, a fast and efficient container for large datasets in Python.  \n",
    "\n",
    "But arrays have several limitations.  One huge limitation is that they are raw containers with numbers, they don't have 'headers', or labels that describe the columns, rows, or the additional dimensions.  This means we need to track separately somewhere what each of the dimensions mean.  Another limitation is that after 3 dimensions, the additional dimensions are impossible toto visualize in the human mind.  For most practical purposes, humans like to think of data in the tabular form, with just rows and columns.  If there are more dimensions, one can have multiple tables.\n",
    "\n",
    "This is where _pandas_ steps in.  Pandas use dataframes, or a spreadsheet like construct where there are rows and columns, and these rows and columns can have names or headings.  Pandas dataframes are easily converted to NumPy arrays, and algorithms will mostly accept a dataframe as an input just as they would an array.\n",
    "\n",
    "### Exploring Tabular Data with Pandas  \n",
    "\n",
    "Tabular data is often the most common data type that is encountered, though ‘unstructured’ data is increasingly becoming common.  Tabular data is two dimensional data – with rows and columns.  The columns are defined and understood, and we generally understand what they contain.  \n",
    "\n",
    " - Data is laid out as a 2-dimensional matrix, whether in a spreadsheet, or R/Python dataframes, or in a database table.  \n",
    " - Rows generally represent individual observations, while columns are the fields/variables.  \n",
    " - Variables can be numeric, or categorical.  \n",
    " - Numerical variables can be integers, floats etc, and are continuous.  \n",
    " - Categorical variables may be cardinal (eg, species, gender), or ordinal (eg, low, medium, high), and belong to a discrete set.  \n",
    " - Categorical variables are also called factors, and levels.  \n",
    " - Algorithms often require categorical variables to be converted to numerical variables.  \n",
    " \n",
    "Unstructured data includes audio, video and other kinds of data that is useful for problems of perception.  Unstructured data will almost invariably need to be converted into structured arrays with defined dimensions, but for the moment we will skip that.  \n",
    "  \n",
    "### Reading data with Pandas\n",
    "\n",
    "Pandas offer several different functions for reading different types of data.\n",
    "> `read_csv` : Load comma separated files  \n",
    "> `read_table` : Load tab separated files  \n",
    "> `read_fwf` : Read data in fixed-width column format (i.e., no delimiters)  \n",
    "> `read_clipboard` Read data from the clipboard; useful for converting tables from web pages  \n",
    "> `read_excel` : Read Excel files  \n",
    "> `read_html` : Read all tables found in the given HTML document  \n",
    "> `read_json` : Read data from a JSON (JavaScript Object Notation) file  \n",
    "> `read_pickle` : Read a pickle file  \n",
    "> `read_sql` : Read results of an SQL query  \n",
    "> `read_sas` : Read SAS files  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a31075-c35b-4dc2-afe9-566621c09a9e",
   "metadata": {},
   "source": [
    "## Other data types in Python\n",
    "\n",
    " - Lists are represented as ```[]```.  Lists are a changeable collection of elements, and the elements can be any Python data, eg strings, numbers, dictionaries, or even other lists.<br>\n",
    " - Dictionaries are enclosed in ```{}```.  These are 'key:value' pairs, where 'key' is almost like a name given to a 'value'.<br>\n",
    " - Sets are also enclosed in ```{}```, except they don't have the colons separating the key:value pairs.  These are collections of items, and they are unordered. <br>\n",
    " - Tuples are collections of variables, and enclosed in ```()```.  They are different from sets in that they are unchangeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7893f117-20e6-48d0-ace5-fb9a6a9eedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example - creating a list\n",
    "\n",
    "empty_list = []\n",
    "list1 = ['a', 2,4, 'python']\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d603f5c3-3e25-4b5d-9ba6-310ab148d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example - creating a dictionary\n",
    "\n",
    "dict1 = {'first': ['John', 'Jane'], 'something_else': (1,2,3)}\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c763d-b3af-47fd-8eff-f8ae0f427307",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1['first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b4ed24-5b63-4c81-8e83-af262803ba9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict1['something_else']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7d614-d204-4ae5-823e-149b056d4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data type of the new variable we created\n",
    "\n",
    "type(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfbd759-b769-42f2-b046-f6c93a0fa8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data type\n",
    "\n",
    "type(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbca950-af3d-45dc-b830-91a7bc0e884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set operations\n",
    "\n",
    "set1 = {1,2,4,5} # Sets can do intersect, union and difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13998a2-02b1-4e41-890f-81ef50fad5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuple example\n",
    "tuple1 = 1, 3, 4 # or\n",
    "tuple1 = (1, 3, 4)\n",
    "tuple1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4517e3-4379-47a7-901d-7cfb7b436b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc11bf68-1882-4d7c-9557-a08209065924",
   "metadata": {},
   "source": [
    "## Loading built-in data sets in Python  \n",
    "\n",
    "Before we move forward with getting into the details with EDA, we will first take a small digressive detour to talk about data sets.  \n",
    "\n",
    "In order to experiment with EDA, we need some data.  We can bring our own data, but for exploration and experimentation, it is often easy to load up one of the many in-built datasets accessible through Python.  These datasets cover the spectrum - from really small datasets to those with many thousands of records, and include text data such as movie reviews and tweets.  \n",
    "\n",
    "We will leverage these built in datasets for the rest of the discussion as they provide a good path to creating reproducible examples. These datasets are great for experimenting, testing, doing tutorials and exercises.\n",
    "\n",
    "The next few headings will cover these in-built datasets.\n",
    "\n",
    " - The Statsmodels library provides access to several interesting inbuilt datasets in Python.  \n",
    " - The datasets available in R can also be accessed through statsmodels.  \n",
    " - The Seaborn library has several toy datasets available to explore.  \n",
    " - The Scikit Learn (sklearn) library also has in-built datasets.   \n",
    " - Scikit Learn also provides a function to generate random datasets with described characteristics (`make_blobs` function)  \n",
    "\n",
    "In the rest of this discussion, we will use these data sets and explore the data.  \n",
    "\n",
    "Some of these are described below, together with information on how to access and use such datasets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c14c7b-dbcc-4881-bb67-65895519dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the regular libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2df44-bca2-467e-b12a-33e95a702b6c",
   "metadata": {},
   "source": [
    "### Loading data from Statsmodels\n",
    "Statsmodels allows access to several datasets for use in examples, model testing, tutorials, testing functions etc.  These can be accessed using `sm.datasets.macrodata.load_pandas()['data']`, where `macrodata` is just one example of a dataset.  Pressing `TAB` after `sm.datasets` should bring up a pick-list of datasets to choose from.  \n",
    "  \n",
    "The commands `print(sm.datasets.macrodata.DESCRLONG)` and `print(sm.datasets.macrodata.NOTE)` provide additional details on the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0793ad7-8c90-4b25-a9de-5780c44191cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load macro economic data from Statsmodels\n",
    "\n",
    "import statsmodels.api as sm\n",
    "df = sm.datasets.macrodata.load_pandas()['data']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81738f-9599-4274-bbc4-3e4bedf8807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the description of the data\n",
    "\n",
    "print(sm.datasets.macrodata.DESCRLONG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee1f29b-5536-49dd-800e-da482fe5b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the data-dictionary for the different columns/fields in the data \n",
    "\n",
    "print(sm.datasets.macrodata.NOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a67a11-e38d-4498-8c1a-6b6986761cde",
   "metadata": {},
   "source": [
    "***\n",
    "### Importing R datasets using Statsmodels\n",
    "Datasets available in R can also be imported using the command `sm.datasets.get_rdataset('mtcars').data`, where `mtcards` can be replaced by the appropriate dataset name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0392a4d-dff8-4e97-91c0-90a27acd8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the mtcars dataset which contains attributes for 32 models of cars\n",
    "\n",
    "mtcars = sm.datasets.get_rdataset('mtcars').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ddbbb-1b8b-416f-b4bb-46b38c7f6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to change directory to a writeable place before running this\n",
    "# eg:\n",
    "# os.chdir('/home/jovyan')\n",
    "# mtcars.to_excel('mtcars.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52859cae-f3fa-41ba-8172-d3c8d504e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b667a78-9901-45c8-8134-8b57a1397d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the famous Iris dataset \n",
    "iris = sm.datasets.get_rdataset('iris').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc8214-3388-4c81-8c8c-2559a32482ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a08c6-ffc2-408a-8cc1-58e90831542c",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "### Datasets in Seaborn\n",
    "Several datasets are accessible through the Seaborn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea0f4b-f0a1-4567-bc54-4df572fe3fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of all the datasets that are available through Seaborn\n",
    "\n",
    "import seaborn as sns\n",
    "sns.get_dataset_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c50d0-c1b4-42ac-a013-3cd8833464e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diamonds dataset\n",
    "\n",
    "diamonds = sns.load_dataset('diamonds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffd67ef-2881-4fe4-9b2f-d98939f3e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b2f23d-b898-4d4e-9317-495993d45fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mpg dataset from Seaborn.  This is similar to the mtcars dataset,\n",
    "# but has a higher count of observations.\n",
    "\n",
    "sns.load_dataset('mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b1d041-393f-4012-b224-dc02c48f9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how many cars from each country in the mpg dataset\n",
    "\n",
    "sns.load_dataset('mpg').origin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf8f7c-298e-472a-9288-016dc03608fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a histogram of the model year\n",
    "\n",
    "sns.load_dataset('mpg').model_year.astype('category').hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3594be40-6484-49c7-ba9a-7cedc8e9737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random dataframe with random data\n",
    "n = 25\n",
    "df = pd.DataFrame(\n",
    "    {'state': list(np.random.choice([\"New York\", \"Florida\", \"California\"], size=(n))), \n",
    "     'gender': list(np.random.choice([\"Male\", \"Female\"], size=(n), p=[.4, .6])),\n",
    "     'education': list(np.random.choice([\"High School\", \"Undergrad\", \"Grad\"], size=(n))),\n",
    "     'housing': list(np.random.choice([\"Rent\", \"Own\"], size=(n))),     \n",
    "     'height': list(np.random.randint(140,200,n)),\n",
    "     'weight': list(np.random.randint(100,150,n)),\n",
    "     'income': list(np.random.randint(50,250,n)),\n",
    "     'computers': list(np.random.randint(0,6,n))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3cabca-e951-4172-b391-7007b08df2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d03c613-ff1f-4397-9d1c-19492895d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 'Old Faithful' eruption data\n",
    "\n",
    "sns.load_dataset('geyser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0937cae9-e918-4feb-820e-0eb4b73ce067",
   "metadata": {},
   "source": [
    "***\n",
    "### Datasets in sklearn\n",
    "Scikit Learn has several datasets that are built-in as well that can be used to experiment with functions and algorithms.  Some are listed below:\n",
    "\n",
    "\n",
    "`load_boston(*[, return_X_y])` Load and return the boston house-prices dataset (regression).  \n",
    "`load_iris(*[, return_X_y, as_frame])` Load and return the iris dataset (classification).  \n",
    "`load_diabetes(*[, return_X_y, as_frame])` Load and return the diabetes dataset (regression).   \n",
    "`load_digits(*[, n_class, return_X_y, as_frame])` Load and return the digits dataset (classification).  \n",
    "`load_linnerud(*[, return_X_y, as_frame])` Load and return the physical excercise linnerud dataset.  \n",
    "`load_wine(*[, return_X_y, as_frame])` Load and return the wine dataset (classification).  \n",
    "`load_breast_cancer(*[, return_X_y, as_frame])` Load and return the breast cancer wisconsin dataset (classification).  \n",
    "\n",
    "Let us import the _wine dataset_ next, and the _California housing datset_ after that.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12608004-5c40-458b-965a-28733534752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X = datasets.load_wine()['data']\n",
    "y = datasets.load_wine()['target']\n",
    "features = datasets.load_wine()['feature_names']\n",
    "DESCR = datasets.load_wine()['DESCR']\n",
    "classes = datasets.load_wine()['target_names']\n",
    "\n",
    "\n",
    "wine_df = pd.DataFrame(X, columns = features)\n",
    "wine_df.insert(0,'WineType', y)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3853c-0655-4214-b5b3-54c467bb485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wine_df[(wine_df['WineType'] != 2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e7d4a-8e77-44d0-b8a4-0c5c9c60fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us look at the DESCR for the dataframe we just loaded\n",
    "\n",
    "print(DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6582f5fa-2ef6-4e1c-b18b-d05f3db97ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# California housing dataset. medv is the median value of the homes\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "X = datasets.fetch_california_housing()['data']\n",
    "y = datasets.fetch_california_housing()['target']\n",
    "features = datasets.fetch_california_housing()['feature_names']\n",
    "DESCR = datasets.fetch_california_housing()['DESCR']\n",
    "\n",
    "cali_df = pd.DataFrame(X, columns = features)\n",
    "cali_df.insert(0,'medv', y)\n",
    "cali_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52feab3-b14c-4798-b777-b7ad070628a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we can look at what the various columns mean\n",
    "\n",
    "print(DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b6e7a-ce2d-4caa-b0ec-94f26c518500",
   "metadata": {},
   "source": [
    "***\n",
    "### Create Artificial Data using sklearn\n",
    "\n",
    "In addition to the built-in datasets, it is possible to create artificial data of arbitrary size to test or explain different algorithms for solving classification (both binary and multi-class) as well as regression problems.\n",
    "\n",
    "One example using the `make_blobs` function is provided below, but a great deal more detail is available at https://scikit-learn.org/stable/datasets/sample_generators.html#sample-generators\n",
    "\n",
    "`make_blobs` and `make_classification` can create multiclass datasets, and `make_regression` can be used for creating datasets with specified characteristics.  Refer to the sklearn documentation link above to learn more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a0751-9e44-4ba4-bc92-7ad76a3f1092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_blobs\n",
    "X, y, centers = make_blobs(n_samples=1000, centers=3, n_features=2,\n",
    "                      random_state=0, return_centers=True, center_box=(0,20),\n",
    "                          cluster_std = 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc108903-5b97-46dc-a44b-5fdb049b2c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(x1=X[:,0], x2=X[:,1], label=y))\n",
    "df = round(df,ndigits=2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3442df-c557-43b2-9f05-42e7d0d4f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(data = df, x = 'x1', y = 'x2', hue = 'label', \n",
    "                alpha = .8, palette=\"deep\",edgecolor = 'None');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29d1684-8bf6-4a37-b782-93a38e2ac8f0",
   "metadata": {},
   "source": [
    "***\n",
    "## Exploratory Data Analysis using Python\n",
    "\n",
    "After all of this lengthy introduction, we are finally ready to get started with actually performing some EDA.\n",
    "\n",
    "As mentioned earlier, EDA is unstructured exploration, there is not a set of set activities you must perform.  Generally, you probe the data, and depending upon what you discover, you ask more questions.\n",
    "\n",
    "Things we will do:\n",
    "\n",
    " - Look at how to read different types of data  \n",
    " - Understand how to access in-built datasets in Python  \n",
    " - Calculate summary statistics covered in the prior class (refer list to the right)  \n",
    " - Perform basic graphing using Pandas to explore the data  \n",
    " - Understand group-by and pivoting functions (the split-apply-combine process)  \n",
    " - Look at pandas-profiling, a library that can perform many data exploration tasks  \n",
    "\n",
    "\n",
    "Pandas is a library we will be using often, and is something we will use to explore data and perform EDA.  We will also use NumPy and SciPy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508a4f3-29f2-4cb5-a6af-bfafca4d06ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the regular libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09208b3-7462-4ff9-b6df-da10898f2aa7",
   "metadata": {},
   "source": [
    "### A note on managing working directories\n",
    "\n",
    "A very basic problem one runs into when trying to load datafiles is the file path - and if the file is not located in the current working directory for Python.  \n",
    "\n",
    "Generally, reading a CSV file is simple - `pd.read_csv` and pointing to the filename does the trick.  If the file is there but pandas returns an error, that could be because the file may not be located in your working directory.  In such a case, enter the complete path to the file.  \n",
    "\n",
    "Alternatively, you can bring the file to your working directory.  To check and change your working directory, use the following code:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45c506-4ec6-4c99-a231-ab08bd3d79ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# To check current working directory:\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18554ded-3f83-46f6-a483-05ca789c2c9d",
   "metadata": {},
   "source": [
    "Or, you could type `pwd` in a cell.  Be aware that pwd should be on the first line of the cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d91531-6af3-4433-93b4-3a03b8ac9a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ebbd89-438a-4c1a-9fdc-0d348898bcfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To change current working directory\n",
    "\n",
    "os.chdir('/home/jovyan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ed094-48a8-444c-8217-e64f82b70d90",
   "metadata": {},
   "source": [
    "### EDA on the diamonds dataset\n",
    "\n",
    "#### Questions we might like answered\n",
    "Below is a repeat of what was said in the introduction to this chapter, just to avoid having to go back to check what we are trying to do. When performing EDA, we want to explore data in an unstructured way, and try to get a 'feel' for the data.  The kinds of questions we may want to answer are:  \n",
    "\n",
    " - How much data do we have - number of rows in the data?\n",
    " - How many columns, or fields do we have in the dataset?\n",
    " - Data types - which of the columns appear to be numeric, dates or strings?\n",
    " - Names of the columns, and do they tell us anything?\n",
    " - A visual review of a sample of the dataset\n",
    " - Completeness of the dataset, are missing values obvious?  Columns that are largely empty?\n",
    " - Unique values for columns that appear to be categorical, and how many observations of each category?\n",
    " - For numeric columns, the range of values (calculated from min and max values)\n",
    " - Distributions for the different columns, possibly graphed\n",
    " - Correlations between the different columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3333ee-eafb-4ae6-b2ab-1bfab36991ab",
   "metadata": {},
   "source": [
    "#### Load data \n",
    "\n",
    "We will start our exploration with the diamonds dataset.  \n",
    "\n",
    "The ‘diamonds’ has 50k+ records, each representing a single diamond.  The weight and other attributes are available, and so is the price.\n",
    "\n",
    "The dataset allows us to experiment with a variety of prediction techniques and algorithms.  Below are the columns in the dataset, and their description.\n",
    "\n",
    "| Column | Description |\n",
    "| --- | --- |\n",
    "| price | price in US dollars (\\\\$326--\\\\$18,823) |\n",
    "| carat | weight of the diamond (0.2--5.01) |\n",
    "| cut | quality of the cut (Fair, Good, Very Good, Premium, Ideal) |\n",
    "| color | diamond colour, from J (worst) to D (best) |\n",
    "| clarity | a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best)) |\n",
    "| x | length in mm (0--10.74) |\n",
    "| y | width in mm (0--58.9) |\n",
    "| z | depth in mm (0--31.8) |\n",
    "| depth | total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79) |\n",
    "| table | width of top of diamond relative to widest point (43--95) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8976c9-7f1b-4940-914e-129178d86801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from seaborn\n",
    "\n",
    "df = sns.load_dataset('diamonds')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde7145-ed92-48b8-9f59-a728b493df1d",
   "metadata": {},
   "source": [
    "#### Descriptive stats\n",
    "Pandas `describe()` function provides a variety of summary statistics.  Review the table below.  Notice the categorical variables were ignored.  This is because descriptive stats do not make sense for categorical variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ea77e-d75e-48a9-b9c4-6f8a8ac7e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us look at some descriptive statistics for the numerical variables\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c63fa67-55d1-401c-9e47-9140b2af985b",
   "metadata": {},
   "source": [
    "`df.info()` gives you information on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65317ea3-91f7-4015-bdaf-9efc5767e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39bded-aac0-43dd-866e-03d89e0a45b1",
   "metadata": {},
   "source": [
    "  \n",
    "  \n",
    "Similarly, `df.shape` gives you a tuple with the counts of rows and columns.\n",
    "\n",
    "Trivia:  \n",
    " - Note there is no `()` after `df.shape`, as it is a property. Properties are the 'attributes' of the object that can be set using methods.\n",
    " - Methods are like functions, but are inbuilt, and apply to an object.  They are part of the class definition for the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea29084-834c-435c-a355-c8e4c7a9c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942663f2-d4ee-4c23-a931-1799fd9a231a",
   "metadata": {},
   "source": [
    "`df.columns` gives you the names of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e982a6ba-f366-4a9f-b6c9-10e56c66d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe7ebfc-4136-4f5a-b323-a51c9b6377ab",
   "metadata": {},
   "source": [
    "**Exploring individual columns**  \n",
    "Pandas provide a large number of functions that allow us to explore several statistics relating to individual variables.\n",
    "\n",
    "\n",
    "| Measures | Function (from Pandas, unless otherwise stated) |\n",
    "| --- | --- |\n",
    "| **Central Tendency** |  |\n",
    "| Mean | `mean()` |\n",
    "| Geometric Mean | `gmean()` (from scipy.stats) |\n",
    "| Median | `median()` |\n",
    "| Mode | `mode()` |\n",
    "| **Measures of Variability** |  |\n",
    "| Range | `max()` - `min()` |\n",
    "| Variance | `var()` |\n",
    "| Standard Deviation | `std()` |\n",
    "| Coefficient of Variation | `std()` / `mean()` |\n",
    "| **Measures of Association** |  |\n",
    "| Covariance | `cov()` |\n",
    "| Correlation | `corr()` |\n",
    "| **Analyzing Distributions** |  |\n",
    "| Percentiles | `quantile()` |\n",
    "| Quartiles | `quantile()` |\n",
    "| Z-Scores | `zscore` (from scipy) |\n",
    "\n",
    "We examine many of these in action below.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df36bb-b9d6-4367-b011-f2adb3939799",
   "metadata": {},
   "source": [
    "#### Functions for descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118157c0-d97c-45a4-be2b-e2a61bc565be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8e7f8-cbf8-4f06-9baf-cf442c6127f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median\n",
    "df.median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd4d8b0-7414-43d7-8300-15ff166f4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode\n",
    "df.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca821f-2e12-4db7-8d3c-8878048f1318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min, also max works as well\n",
    "\n",
    "df.min(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7d3a0c-ee2f-4326-8ec2-8982b9965ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance\n",
    "df.var(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd93a4-672a-4978-916a-b33f3e1b913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Deviation\n",
    "df.std(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d24a21-8a0b-41c7-8a8c-9ff3c6c7aa75",
   "metadata": {},
   "source": [
    "#### Some quick histograms  \n",
    "Histograms allow us to look at the distribution of the data.  The `df.colname.hist()` function allows us to create quick histograms (or column charts in case of categorical variables).  \n",
    "\n",
    "Visualization using Matplotlib is covered in a different chapter.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae99fe-69b0-4617-8550-d71343f47bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick histogram\n",
    "\n",
    "df.carat.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02911f80-a0d0-48ec-8240-80ec0b727cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.depth.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb9c3d7-99c9-4b74-9fb1-27024526bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cut.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67314371-1169-43a8-ac3c-108fe028cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All together\n",
    "df.hist(figsize=(16,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e244e-0d00-4791-87b2-00003fb9f1ba",
   "metadata": {},
   "source": [
    "#### Calculate range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336231fb-f0dc-44b1-b94d-384a350b1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate the range manually\n",
    "\n",
    "df.depth.max() - df.depth.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d6091-8836-4f27-9c1f-2a526dbb505f",
   "metadata": {},
   "source": [
    "#### Covariance and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f8575f-1560-4f2b-aca1-bd60786984cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us do the covariance matrix, which is a one-liner with pandas\n",
    "\n",
    "df.cov(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39276352-9eb8-43aa-b011-cdeee89f3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the correlation matrix - another one-liner\n",
    "\n",
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb6730-3367-4766-8098-8c03279175cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also calculate the correlations individually between given variables\n",
    "\n",
    "df[['carat', 'depth']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1718ba0c-8cf8-447b-b98b-bb025cd9a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a heatmap of correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07083e01-119f-46b5-98b6-f9f6392d83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e44cd-4070-4452-8ac7-65044841b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can calculate phi-k correlations as well\n",
    "import phik\n",
    "X = df.phik_matrix()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bca0ff-6688-4871-9e03-7b5124b8a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63083922-cb0a-4e75-a54f-f90bcf640cc4",
   "metadata": {},
   "source": [
    "**Detailed Phi-k correlation report**  \n",
    "```python\n",
    "from phik import report\n",
    "phik.report.correlation_report(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5c5f6-57c5-4898-922a-def3b6a35baa",
   "metadata": {},
   "source": [
    "#### Quantiles to analyze the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc071ed5-ac6a-4c53-b0b3-0c9805e799e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating quantiles\n",
    "# Here we calculate the 30th quantile\n",
    "\n",
    "\n",
    "df.quantile(0.30, numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e91cf-a40d-4c8c-a160-c46844e8ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating multiple quantiles\n",
    "\n",
    "df.quantile([.1,.3,.5,.75], numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7ee0a6-82cc-49e7-b900-6b9422929539",
   "metadata": {},
   "source": [
    "#### Z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14271d0-ad10-4172-bda5-58b63f106d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-scores for two of the columns (x - mean(x))/std(x)\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "zscores = zscore(df[['carat', 'depth']])\n",
    "\n",
    "\n",
    "# Verify z-scores have mean of 0 and standard deviation of 1:\n",
    "print('Z-scores: \\n', zscores, '\\n')\n",
    "\n",
    "print('Mean is: ', zscores.mean(axis = 0), '\\n')\n",
    "\n",
    "print('Std Deviation is: ', zscores.std(axis = 0), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f92e8c-f6de-45a0-84df-9031a3a2f889",
   "metadata": {},
   "source": [
    "#### Dataframe information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b6d0fd-03c1-4037-99df-4eb8948c23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some dataframe information\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1d936f-17d8-411a-b6f2-8e113026ad5b",
   "metadata": {},
   "source": [
    "#### Names of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965521ea-6b81-4abb-a72e-9152edbb162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad772f64-7d31-4a16-ae6d-0c833bfff094",
   "metadata": {},
   "source": [
    "#### Other useful functions  \n",
    "> Sort: `df.sort_values(['price', 'table'], ascending = [False, True]).head()`  \n",
    "> Unique values: `df.cut.unique()`  \n",
    "> Count of unique values: `df.cut.nunique()`  \n",
    "> Value Counts: `df.cut.value_counts()`  \n",
    "> Take a sample from a dataframe: `diamonds.sample(4)` (or n=4)  \n",
    "> Rename columns: `df.rename(columns = {'price':'dollars'}, inplace = True)`  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbc2a70-2b39-431b-906c-20b7844fea3d",
   "metadata": {},
   "source": [
    "## _Split-Apply-Combine_ \n",
    "\n",
    "The phrase Split-Apply-Combine was made popular by Hadley Wickham, who is the author of the popular dplyr package in R.  His original paper on the topic can be downloaded at https://www.jstatsoft.org/article/download/v040i01/468\n",
    "\n",
    "Conceptually, it involves:  \n",
    " - Splitting the data into sub-groups based on some filtering criteria  \n",
    " - Applying a function to each sub-group and obtaining a result  \n",
    " - Combining the results into one single dataframe.  \n",
    "\n",
    "Split-Apply-Combine does not represent three separate steps in data analysis, but a way to think about solving problems by breaking them up into manageable pieces, operate on each piece independently, and put all the pieces back together.  \n",
    "\n",
    "In Python, the Split-Apply-Combine operations are implemented using different functions such as pivot, pivot_table, crosstab, groupby and possibly others. \n",
    "\n",
    "_Ref: http://www.jstatsoft.org/v40/i01/_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd070b-db11-4773-aad9-a264ed0c34cf",
   "metadata": {},
   "source": [
    "### Stack\n",
    "Even though `stack` and `unstack` do not pivot data, they reshape a data in a fundamental way that deserves a reference alongside the standard split-apply-combine techniques.\n",
    "\n",
    "What _stack_ does is to completely flatten out a dataframe by bringing all columns down against the index.  The index becomes a multi-level index, and all the columns show up against every single row.  \n",
    "\n",
    "The result is a pandas series, with as many rows as the rows times columns in the original dataset.\n",
    "\n",
    "You can then move the index into the columns of a dataframe by doing `reset_index()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb90d7-4dbc-4c5e-827f-8aa233b70e83",
   "metadata": {},
   "source": [
    "Let us first consider a simpler dataframe with just a few entries.  \n",
    "\n",
    "**Example 1**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47402cc1-a303-4b55-a21b-254657dd9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[9, 10], [14, 30]],\n",
    "                                    index=['cat', 'dog'],\n",
    "                                    columns=['weight-lbs', 'height-in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7974cea-d6f8-4490-a4f1-32901d0cbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf150b-4287-4fdb-ae28-b9394b337e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2202a871-c8c5-41a0-9279-95fde448a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this to a dataframe\n",
    "pd.DataFrame(df.stack()).reset_index().rename({'level_0': 'animal', 'level_1':'measure', 0: 'value'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3db608-b446-4993-8429-a2232f845926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e0369-c3d6-4a44-b504-9aac17b6023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb5a41-4559-4e98-83ff-430d4553dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stack().index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72110a-b809-4479-9c85-f21cc8e7c50c",
   "metadata": {},
   "source": [
    "**Example 2:**  \n",
    "Now we look at a larger dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad456d34-06b6-4ff2-bc8a-91d9d815c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "iris = sm.datasets.get_rdataset('iris').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12cd7d-bb0c-472f-a22c-1de2a9a29409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us look at the original data before we stack it\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50547a3-0beb-4cab-870a-1f1ff83fba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037051c0-5336-4295-88d9-a0f7fb922527",
   "metadata": {},
   "source": [
    "We had 150 rows and 5 columns in our original dataset, and we would therefore expect to have 150*5 = 750 items in our stacked series.  Which we can verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c7b61-122e-4c62-abe6-946941eb8dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.shape[0] * iris.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839caf1a-0fe1-4888-8f69-ecb925f5881d",
   "metadata": {},
   "source": [
    "**Example 3:**  \n",
    "We stack the mtcars dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1af4fb-0a52-4d74-9e4d-74bcd287ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars = sm.datasets.get_rdataset('mtcars').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7671910a-279c-4de2-b5f8-1b5e7f57f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c90cf-7f3b-46e4-8c04-bb770b249b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706bd6b0-b6c8-4bad-bf8e-13ecbc7d72ee",
   "metadata": {},
   "source": [
    "### Unstack\n",
    "Unstack is the same as the stack of the transpose of a dataframe.\n",
    "\n",
    "So you flip the rows and columns of a database, and you then do a stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa27a09-4cd8-4b00-8aa3-6958566ed76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d302791e-8841-433a-9366-3a3bfd44da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e868f-45d1-4380-a220-3d349cfa5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.transpose().stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f464c-99da-471e-8181-4d6668317a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the row count\n",
    "mtcars.stack().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2516b-4448-498e-9cf1-0af16411aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected row count in stack\n",
    "mtcars.shape[0] * mtcars.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0afd272-04e0-46d2-9115-72adc357bbfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pivot table\n",
    "\n",
    "A powerful way the idea behind _split-apply_combine_ is implemented is through pivot tables.  Pivot tables allow reshaping the data into useful summaries.  Pivot tables are widely used by Excel users, and you will find them used in reports, presentations and analysis of all types.  Pandas offers a great deal of flexibility for creating pivot tables using the pivot_table function.  \n",
    "\n",
    "The pivot_table function is essentially a copy of the Excel functionality.  \n",
    "\n",
    "- `index` - On the left is the index, and you can specify multiple columns there.  Each unique value in that index column will have a separate line.  Under each of these lines, there will be a line for each value of the second column in the index, and so on. \n",
    "- `columns` - On the top are the columns, again in the order in which specified in the parameters to the function.  The first column specified is on the top, and underneath will be all unique values of that column.  This is followed by the next column in the list, and so on.  \n",
    "- `values` - Inside the table itself are values derived from the columns named in the _values_ parameter.  The default for values is the mean of the value columns, but you can change it to other functions using aggfunc.  \n",
    "- `aggfunc` - Next is aggfunc.  You can specify any function from any library that returns a single value.  \n",
    "\n",
    "**CAUTION**  \n",
    "It is really easy to get pivot tables wrong and get something incomprehensible.  To create a sensible pivot table, it makes sense to:\n",
    "- have categorical columns in both index and columns.  If you use numerical variables in either, the length of your columns/rows will explode unless the number of unique values is limited.  \n",
    "- have columns in the values parameter that lend themselves to the aggregation function specified.  So if you specify a categorical column for values, and ask pandas to show the mean, you will be setting yourself up for disappointment.  If you are using a categorical column for values, be sure to use an appropriate aggregation function eg `count`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e49d47d-c8fd-41db-871a-aad5833bb255",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7932d979-68f1-4c1a-9163-df242a5a5498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some transformations to help understand pivots better\n",
    "mtcars.cyl = mtcars.cyl.replace({4: 'Four', 6: 'Six', 8: 'Eight'} )\n",
    "mtcars.am = mtcars.am.replace({1: 'Automatic', 0: 'Manual'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf89b8b3-7d68-4b18-9f39-c43318821037",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars = mtcars.head(8)\n",
    "mtcars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d87678-124b-4f22-beba-fa708d4bfbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.pivot_table(index = ['gear','cyl'],\n",
    "                   values = ['wt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151266d8-8d26-4cf0-b890-35a87e581e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mtcars.pivot_table(index = ['am', 'gear'],\n",
    "                   columns = ['cyl'],\n",
    "                   values = ['wt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b99ee-4203-4851-9d36-6feeb40ffc25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mtcars.pivot_table(index = ['am', 'gear'],\n",
    "                  columns = ['cyl'],\n",
    "                  values = ['wt'],\n",
    "                  aggfunc = ['mean', 'count', 'median', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0e7c9-f183-452e-84c9-38c2a5f9ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = sns.load_dataset('diamonds')\n",
    "\n",
    "diamonds.pivot_table(index = ['clarity', 'cut'],\n",
    "              columns = ['color'],\n",
    "              values = ['depth', 'price', 'x'],\n",
    "              aggfunc = {'depth': np.mean,\n",
    "                        'price': [min, max, np.median],\n",
    "                        'x': np.median}\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bbb9f9-6dfe-4e57-982f-2891b2d603ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us create a dataframe with random variables\n",
    "np.random.seed(1)\n",
    "n = 2500\n",
    "df = pd.DataFrame(\n",
    "    {'state': list(np.random.choice([\"New York\", \"Florida\", \"California\"], size=(n))), \n",
    "     'gender': list(np.random.choice([\"Male\", \"Female\"], size=(n), p=[.4, .6])),\n",
    "     'education': list(np.random.choice([\"High School\", \"Undergrad\", \"Grad\"], size=(n))),\n",
    "     'housing': list(np.random.choice([\"Rent\", \"Own\"], size=(n))),     \n",
    "     'height': list(np.random.randint(140,200,n)),\n",
    "     'weight': list(np.random.randint(100,150,n)),\n",
    "     'income': list(np.random.randint(50,250,n)),\n",
    "     'computers': list(np.random.randint(0,6,n))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229dd604-92f0-4242-8a4c-eb295e35c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d5650a-b122-4866-82dc-1d77cf0b00f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index = ['gender'],\n",
    "               columns = ['education'],\n",
    "               values = ['income'],\n",
    "               aggfunc = ['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed2e617-7d2e-4464-af58-c86e656564e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index = ['state'],\n",
    "               columns = ['education', 'housing'],\n",
    "               values = ['gender', 'computers'],\n",
    "               aggfunc = {'gender': [len], 'computers': [np.median, 'mean']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e3df7-d488-42f1-bbd0-c5f934922332",
   "metadata": {},
   "source": [
    "### Pivot\n",
    "Pivot is a simpler version of pivot_table.  It cannot do any aggregation function, it just shows the values of the 'value' columns at the intersection of the 'index' and the 'columns'.\n",
    "\n",
    "There are three parameters for pivot:\n",
    "1. index - which columns in the dataframe should be the index.  This is optional. If not specified, it uses the index of the dataframe.  \n",
    "2. columns - which dataframe columns should appear on the top as columns in the result.  For each entry in the column parameter, it will create a separate column for each unique value of that column.  So if 'carb' can be 1, 2 or 4, it will show 1, 2 and 4 on the top.\n",
    "3. values - which column's values to show at the intersection of index and columns.  If there is more than one value (even if the multiple values are identical), pivot will throw an error. (for example, in mtcars_small, if yuou put cyl 4,6,8 on the left as index, and am 0,1 on the top as columns, and mpg as values, you have two cars at their intersection.)\n",
    "\n",
    "Pivot can be better than pivot_table as it brings in the value at the intersection of index and columns as-is, which is what you need sometimes without having to add, mean, or count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fccd90e-025a-4cdd-86d2-3de081eaca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars = sm.datasets.get_rdataset('mtcars').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3167c7-536a-4bc3-a393-b0774f2292ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e064840-277f-401e-8270-e2a59030ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars = mtcars.reset_index().rename(columns={'rownames': 'car'})\n",
    "mtcars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6eae6-cdd8-4d1f-a779-3581e55b1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars_small = mtcars.iloc[1:8, [0, 1, 2, 4, 8 , 9]]\n",
    "mtcars_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee7c5d-58c4-43d3-ae9c-b51fff29ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars_small.pivot(index = 'car', columns = 'cyl', values = 'mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40324709-32b4-4f39-838e-fbe96b597766",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars_small.pivot(index = 'car', columns = 'cyl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0535c900-d416-4167-9d51-870dfeef5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars_small.pivot(index = 'car', columns = ['am'], values=['mpg', 'vs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c582394-c53a-466f-b525-320a55f8c159",
   "metadata": {},
   "source": [
    "**Sometimes you may wish to use the index of a dataframe directly, as opposed to moving it into its own column first.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e50be-06d8-4baf-a3c8-d8ddae029289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[0, 1, 2], [2, 3, 5], [6,7,8],],\n",
    "                                    index=['cat', 'dog', 'cow'],\n",
    "                                    columns=['weight', 'height', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0dbf9f-5ea1-44e0-a42c-aecef3735b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80271d-767e-4572-af39-73d0561e15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot(index = [ 'weight'], columns = ['height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc50a4-b6da-4dff-98a9-d612cfad1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now also use the native index of the dataframe\n",
    "\n",
    "df.pivot(index = [df.index, 'weight'], columns = ['height'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af77ad11-1a96-49d3-907e-70a18b657fbf",
   "metadata": {},
   "source": [
    "Now the same thing fails if there are duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce583e5e-3871-4ded-a05b-5a87cd232554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['cat', 0, 1, 2], ['dog', 2, 3, 5], ['cow', 6,7,8], ['pig', 6,7,8],],\n",
    "                                    columns=['animal', 'weight', 'height', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f70aab9-3f58-42ac-9960-051e582b0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a3c683-53ae-41c6-b0fa-713d90d4d9bf",
   "metadata": {},
   "source": [
    "The below will fail as there are duplicates.\n",
    "```python\n",
    "df.pivot(index = [ 'weight'], columns = ['height'])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed72a5-85da-445a-a1f9-bf04b9b7ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We consider only the first 3 rows of this new dataframe.\n",
    "# Look how in the values we have a categorical variable.\n",
    "\n",
    "df.iloc[:3].pivot(index = 'weight', columns = 'height', values = 'animal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cbdafb-9170-4325-be7d-8cec0ed8f7d0",
   "metadata": {},
   "source": [
    "### Crosstab\n",
    "\n",
    "Cross computes a frequency table given an index and columns of categorical variables (as a data frame column, series, or numpy array).  However it is possible to specify an aggfunc as well, that makes it like a pivot_table.  \n",
    "\n",
    "You can pass normalize = True, or index, or columns, and it will normalize based on totals, or by the rows or by the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a8ae4-a42f-4bb1-ab33-a9318ee2a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('diamonds')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6366c-1946-41d2-8bed-8f52c9a8f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "pd.crosstab(df.cut, df.color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8754e81-91af-43e2-9dda-48641820ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With margins\n",
    "pd.crosstab(df.cut, df.color, margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43679644-3b9c-4da1-a01c-9068fd6c6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With margins and normalized\n",
    "pd.crosstab(df.cut, df.color, margins = True, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449fe12-2e30-42b9-bc62-4644666d7f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized by index.  Rows total to 1.  See how the total column 'All' has \n",
    "# disappeared from rows.  But it has remained for the columns\n",
    "pd.crosstab(df.cut, df.color, margins = True, normalize = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9454d95-b46e-4a5b-880d-9fac4b6428c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized by columns\n",
    "pd.crosstab(df.cut, df.color, margins = True, normalize = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb64dae-f807-43bb-9a24-96a37cba2edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also pass multiple series for both the index and columns\n",
    "pd.crosstab([df.cut, df.color], [df.clarity])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f1b7a6-f97d-4ca8-8732-fd083e8f9dcb",
   "metadata": {},
   "source": [
    "### Melt\n",
    "\n",
    "Melt is similar to Stack() but unlike stack it returns a dataframe, not a series with a multi-level index.  A huge advantage is that unlike stack, you can _freeze_ some of the columbns and stack the rest.  \n",
    "\n",
    "In melt, you specify id_vars (index variables) - these are the columns that stay untouched, and then the value_vars, that get stacked.  If value_vars are not specified, all columns other than id_vars get stacked.\n",
    "\n",
    "**Opposite of melt is pivot.  Pivot applies no aggfunc, just lists the values at the intersection of categorical vars it picks up from a melted dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2774fd4-b762-4d8b-a361-b2c701566e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us create a dataframe with random variables\n",
    "np.random.seed(1)\n",
    "n = 10\n",
    "df = pd.DataFrame(\n",
    "    {'state': list(np.random.choice([\"New York\", \"Florida\", \"California\"], size=(n))), \n",
    "     'gender': list(np.random.choice([\"Male\", \"Female\"], size=(n), p=[.4, .6])),\n",
    "     'education': list(np.random.choice([\"High School\", \"Undergrad\", \"Grad\"], size=(n))),\n",
    "     'housing': list(np.random.choice([\"Rent\", \"Own\"], size=(n))),     \n",
    "     'height': list(np.random.randint(140,200,n)),\n",
    "     'weight': list(np.random.randint(100,150,n)),\n",
    "     'income': list(np.random.randint(50,250,n)),\n",
    "     'computers': list(np.random.randint(0,6,n))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8cf616-428d-411d-a609-b2724bb9c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67c3ee-8848-4878-baa9-18a28edb5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to demonstrate, melt-ing the first five rows of the df\n",
    "df.head().melt(id_vars = ['state', 'gender'], value_vars = ['computers', 'income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffbcef1-62b4-4a6e-a654-6da72667d7c2",
   "metadata": {},
   "source": [
    "### Groupby  \n",
    "Groupby returns a groupby object, to which other agg functions can be applied.  \n",
    "\n",
    "- Groupby does the 'split' part in the split-apply-combine framework.\n",
    "\n",
    "- You do the 'apply' using an aggregation function against the groupby object.  \n",
    "\n",
    "- 'Combine' doesn't need to be done separately as it is done automatically after the aggregation function is applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fef8bc-91eb-4e69-b73a-32a6a70ef0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example\n",
    "\n",
    "df.groupby(['state', 'gender']).agg({\"height\": \"mean\", \"weight\": \"sum\", \"housing\": \"count\", \"education\": \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a283a04-815d-4894-a67c-38b238ddbd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation is done only for the columns for which an aggregation function is specified\n",
    "\n",
    "df.groupby(['state', 'gender']).agg({\"height\": \"mean\", \"weight\": \"sum\", \"housing\": \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b272953-2d27-40e7-9859-286cf9ab91eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['state', 'gender']).head(1).agg({\"height\": \"mean\", \"weight\": \"sum\", \"housing\": \"count\", \"education\": \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942301ac-e04b-4b0f-a25b-cf60ab6e34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = df.groupby(['state', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec6b36-b901-4973-b9da-4c9b99c7ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to look at groups in a groupby:\n",
    "list(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75916d-8925-42ec-9784-93b21bb36ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(group)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec7a4b7-18a4-44d7-b484-feffae308293",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f673f11-bc9f-4b09-9adc-879b9ea5c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at groups in a groupby - more elegant version:\n",
    "for group_name, combined in group:\n",
    "    print(group_name)\n",
    "    print(combined)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ad80a-66f4-4016-b60b-8cc4791c37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to look at a specific group - the group categorical values have to be entered as a tuple\n",
    "group.get_group(('New York', 'Male'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb57d86-838e-4903-9dfb-1d199cbc4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first row of each group\n",
    "\n",
    "group.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a47637-2a50-4cbc-ac60-9caf982d9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first record of each group.\n",
    "# For this to be useful, sort the original df by the right columns before groupby.\n",
    "\n",
    "group.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc6777-b3e6-45c8-9c76-6b7008abc49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats for all groups\n",
    "\n",
    "group.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a461d14a-d4a4-4104-9e43-833627ab645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, if you prefer this\n",
    "\n",
    "group.describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb625b9c-b853-4596-97c3-fa08c6e1d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of rows in each group.\n",
    "# You can pd.DataFrame it, and reset_index() to clean up\n",
    "\n",
    "group.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fca8b5-f6f7-4943-bbab-6d7d215eb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting min and max values in each group using groupby\n",
    "\n",
    "mtcars = sm.datasets.get_rdataset('mtcars').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70199540-a3c8-47b3-9058-797d7e60c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a297a8bb-cee5-468e-9238-e9a3ef2ed759",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.groupby(['cyl']).agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8d0b9-a7e5-40d2-a0fe-e9c4c22b14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which rows have the min values in each column of a groupby.  The index of the row is returned\n",
    "# Which in this case is happily the car name, not an integer\n",
    "\n",
    "mtcars.groupby(['cyl']).idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73609250-9964-4674-ab2a-057f65397e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.groupby(['cyl']).idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99185098-ceae-4286-bb9b-a8a3b60ddf53",
   "metadata": {},
   "source": [
    "**`rename` columns with Groupby**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dcf1bd-1031-4725-b588-9a8f2f959efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We continue the above examples to rename the aggregated columns we created using groupby\n",
    "\n",
    "diamonds.groupby('cut').agg({\"price\": \"sum\", \n",
    "                             \"clarity\": \"count\"}).rename(columns = {\"price\": \"total_price\", \"clarity\": \"diamond_count\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84164091-8589-4fbb-ad8b-de6146d521a9",
   "metadata": {},
   "source": [
    "## Pandas Profiling\n",
    "### Profiling our toy dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3611a471-b372-4198-bef3-6b875607481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/jovyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37724a9f-842c-4f5e-bc9c-e86f82754173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ydata_profiling\n",
    "profile = ydata_profiling.ProfileReport(df, title = 'My EDA', minimal=True).to_file(\"output.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c1e1a-ccd0-409f-b8a5-1c64c5ac24d9",
   "metadata": {},
   "source": [
    "--  \n",
    "  \n",
    "Now check out output.html in your folder.  You can right click and open output.html in the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70abc2-7c92-4b59-a4dd-0cd03cac1dd2",
   "metadata": {},
   "source": [
    "### Pandas Profiling on the Diamonds Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d1d818-7850-4078-891f-b9bca5c3aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and the diamonds dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import ydata_profiling\n",
    "import phik\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = sns.load_dataset('diamonds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98d34a-141e-4a7d-a2cc-26d59cee730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ydata_profiling.ProfileReport(df, title = 'My EDA', minimal=True).to_file(\"output.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78add3-6dea-464a-ad95-2b8b1561658a",
   "metadata": {},
   "source": [
    "***\n",
    "With this, we end our discussion on EDA.  We have seen how we can analyze data, get statistics, distributions and identify key themes.  Since this is a problem that has to be solved for every day by lots of analysts, there are many libraries devoted to EDA that automate much of the work.  We looked at one - `pandas_profiling`.  If you search, you will find several more, and may even find something that work best for your use case.\n",
    "\n",
    "If you have been able to follow thus far, you are all set to explore any numerical data in a tabular form.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
